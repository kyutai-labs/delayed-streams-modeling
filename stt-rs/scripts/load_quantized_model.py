#!/usr/bin/env python3

import torch
import safetensors.torch


def load_quantized_weights():
    """Load and dequantize the Moshi STT 1B weights."""

    # Load the quantized weights using safetensors
    quantized_data = safetensors.torch.load_file(
        "./moshi_stt_1b_uint8/quantized_model.safetensors", device="cpu"
    )

    # Note: The safetensors file is automatically generated by quantize_model.py
    # and can be used directly with Rust

    # Dequantize the weights
    dequantized_state_dict = {}

    for name, data in quantized_data.items():
        if isinstance(data, dict) and "quantized" in data:
            # Dequantize
            quantized = data["quantized"]
            scale = data["scale"]
            zero_point = data["zero_point"]
            original_dtype = data["original_dtype"]

            # Dequantize: float_val = scale * (quantized - zero_point)
            dequantized = (quantized.to(torch.float32) * scale + zero_point).to(
                original_dtype
            )
            dequantized_state_dict[name] = dequantized
        else:
            # Non-quantized tensor
            dequantized_state_dict[name] = data

    print("Quantized weights loaded and dequantized successfully!")
    return dequantized_state_dict


if __name__ == "__main__":
    weights = load_quantized_weights()
    print(f"Loaded {len(weights)} weight tensors")
